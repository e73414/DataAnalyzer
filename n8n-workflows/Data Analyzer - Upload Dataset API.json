{"name":"Data Analyzer - Upload Dataset API","nodes":[{"parameters":{"model":{"__rl":true,"mode":"list","value":"gpt-5-mini"},"responsesApiEnabled":false,"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[-976,704],"id":"c508f394-a693-4150-a5e9-f5f54c1307d8","name":"OpenAI Chat Model","credentials":{"openAiApi":{"id":"ayhC2xZ3iWv4ZkDW","name":"OpenAi account"}}},{"parameters":{"httpMethod":"POST","path":"upload-dataset","responseMode":"responseNode","options":{}},"type":"n8n-nodes-base.webhook","typeVersion":2,"position":[-1712,-80],"id":"3d26178d-e579-471e-ab4d-5f366913331c","name":"Webhook","webhookId":"upload-dataset-webhook"},{"parameters":{"jsCode":"var webhookData = $input.first().json.body;\nvar base64Data = webhookData.csvData;\nif (!base64Data) {\n  throw new Error(\"No csvData found in request\");\n}\n\nvar datasetName = webhookData.datasetName || \"Unnamed Dataset\";\nvar description = webhookData.description || \"\";\nvar email = webhookData.email || \"\";\n\nvar csvText = Buffer.from(base64Data, \"base64\").toString(\"utf-8\");\n\n// Strip BOM if present\nif (csvText.charCodeAt(0) === 0xFEFF) {\n  csvText = csvText.slice(1);\n}\n\n// --- MULTILINE-AWARE CSV PARSER ---\nfunction parseCSV(text) {\n  const rows = [];\n  let row = [];\n  let cell = '';\n  let inQuotes = false;\n\n  for (let i = 0; i < text.length; i++) {\n    const char = text[i];\n    const next = text[i + 1];\n\n    if (char === '\"') {\n      if (inQuotes && next === '\"') {\n        cell += '\"';\n        i++;\n      } else {\n        inQuotes = !inQuotes;\n      }\n    } else if (char === ',' && !inQuotes) {\n      row.push(cell.trim());\n      cell = '';\n    } else if (!inQuotes && (char === '\\n' || char === '\\r')) {\n      if (char === '\\r' && next === '\\n') i++;\n      row.push(cell.trim());\n      if (row.some(v => v !== '')) {\n        rows.push(row);\n      }\n      row = [];\n      cell = '';\n    } else {\n      cell += char;\n    }\n  }\n\n  // Flush final row\n  if (cell || row.length) {\n    row.push(cell.trim());\n    if (row.some(v => v !== '')) {\n      rows.push(row);\n    }\n  }\n\n  return rows;\n}\n// ----------------------------------\n\nvar allRows = parseCSV(csvText);\n\nif (allRows.length < 2) {\n  throw new Error(\"CSV must have header and data rows\");\n}\n\nvar headers = allRows[0];\nvar rows = [];\n\nfor (var i = 1; i < allRows.length; i++) {\n  var values = allRows[i];\n  var row = {};\n  for (var j = 0; j < headers.length; j++) {\n    row[headers[j]] = values[j] !== undefined ? values[j] : \"\";\n  }\n  rows.push({ json: row });\n}\n\nif (rows.length === 0) {\n  throw new Error(\"No data rows found\");\n}\n\n$execution.customData.set(\"datasetName\", datasetName);\n$execution.customData.set(\"description\", description);\n$execution.customData.set(\"email\", email);\n\nreturn rows;\n"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[-1504,-80],"id":"a4a98616-bdf1-455e-a000-80530cb3054a","name":"Parse CSV"},{"parameters":{"jsCode":"var items = $input.all();\nif (items.length === 0) return { error: \"No data received.\" };\n\nvar datasetName = $execution.customData.get(\"datasetName\") || \"Test\";\nvar datasetDesc = $execution.customData.get(\"description\") || \"\";\nvar email = $execution.customData.get(\"email\") || \"\";\n\nfunction detectType(val) {\n  if (val === null || val === undefined || String(val).trim() === \"\") return \"null\";\n  var str = String(val).trim();\n\n  // 1. Enhanced Date Detection (Strict ISO, US Slanted, and Dash formats)\n  var strictDate = /^\\d{4}-\\d{2}-\\d{2}$|^\\d{1,2}[\\/-]\\d{1,2}[\\/-]\\d{2,4}$/;\n  // Also check if it's a valid date object string (like \"2023-10-27T10:00:00Z\")\n  if (strictDate.test(str) || !isNaN(Date.parse(str)) && isNaN(str)) {\n    return \"date\";\n  }\n\n  // 2. Boolean Detection\n  if (str.toLowerCase() === \"true\" || str.toLowerCase() === \"false\") return \"bool\";\n\n  // 3. Numeric Detection (Cleaned of currency/commas)\n  var cleanNum = str.replace(/[$,]/g, \"\");\n  if (cleanNum !== \"\" && !isNaN(cleanNum)) {\n    if (str.indexOf(\".\") !== -1 || Math.abs(parseFloat(cleanNum)) > 999999) {\n      return \"real\";\n    }\n    return \"int\";\n  }\n\n  return \"string\";\n}\n\nfunction getWinnerType(current, next) {\n  if (!current || current === \"null\") return next;\n  if (next === \"null\") return current;\n  \n  // Hierarchy: String kills everything. \n  // Dates should stay Dates unless mixed with text.\n  if (current === \"string\" || next === \"string\") return \"string\";\n  \n  // If we have mixed Date and Numbers, we usually default to String\n  if ((current === \"date\" && next !== \"date\") || (next === \"date\" && current !== \"date\")) {\n    return \"string\";\n  }\n\n  if (current === \"real\" || next === \"real\") return \"real\";\n  if (current === \"int\" && next === \"int\") return \"int\";\n  \n  return current;\n}\n\nvar columnTypes = {};\nitems.forEach(function(item) {\n  var entries = Object.entries(item.json);\n  for (var i = 0; i < entries.length; i++) {\n    var key = entries[i][0];\n    var value = entries[i][1];\n    var type = detectType(value);\n    columnTypes[key] = getWinnerType(columnTypes[key], type);\n  }\n});\n\nvar counters = { string: 1, real: 1, int: 1, date: 1, bool: 1 };\nvar mapping = {};\nvar dictionary = {};\n// Trim and deduplicate headers (trim before sort to group identical trimmed names)\nvar headers = [...new Set(Object.keys(columnTypes).map(k => k.trim()))].sort();\n// Rebuild columnTypes with trimmed keys\nvar trimmedColumnTypes = {};\nObject.keys(columnTypes).forEach(k => {\n  var tk = k.trim();\n  trimmedColumnTypes[tk] = getWinnerType(trimmedColumnTypes[tk], columnTypes[k]);\n});\ncolumnTypes = trimmedColumnTypes;\n\nfor (var i = 0; i < headers.length; i++) {\n  var header = headers[i].trim();\n  var type = columnTypes[header];\n  if (type === \"null\") type = \"string\";\n\n  // This creates column names like date1, date2, etc.\n  var dbColumn = type + counters[type];\n  mapping[header] = dbColumn;\n  dictionary[dbColumn] = { \n    original_name: header, \n    data_type: type \n  };\n  counters[type]++;\n}\n\nreturn {\n  dataset_name: datasetName,\n  dataset_summary: datasetDesc,\n  owner_email: email,\n  column_mapping: mapping,\n  column_dictionary: dictionary,\n  total_row_count: items.length\n};"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[-1312,-80],"id":"fc31cd79-8d30-4bb6-ba19-92608e28272c","name":"Mapping Logic"},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":3},"conditions":[{"id":"check-summary","leftValue":"={{ $json.dataset_summary }}","rightValue":"","operator":{"type":"string","operation":"empty","singleValue":true}}],"combinator":"and"},"options":{}},"type":"n8n-nodes-base.if","typeVersion":2.3,"position":[-1104,-80],"id":"253ad3e9-4129-4413-adfd-0fadcd32fb71","name":"If Summary Empty"},{"parameters":{"jsCode":"var items = $(\"Parse CSV\").all();\nif (items.length === 0) return [];\n\nvar shuffled = items.slice();\nfor (var i = shuffled.length - 1; i > 0; i--) {\n  var j = Math.floor(Math.random() * (i + 1));\n  var temp = shuffled[i];\n  shuffled[i] = shuffled[j];\n  shuffled[j] = temp;\n}\n\nreturn shuffled.slice(0, 100);"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[-912,-176],"id":"b1548f21-a867-40c8-8125-dd71e103a95d","name":"Sample Data"},{"parameters":{"assignments":{"assignments":[{"id":"a1","name":"dataset_name","value":"={{ $(\"Mapping Logic\").first().json.dataset_name }}","type":"string"},{"id":"a2","name":"dataset_summary","value":"={{ $json.cleaned_summary }}","type":"string"},{"id":"a6","name":"owner_email","value":"={{ $(\"Mapping Logic\").first().json.owner_email }}","type":"string"},{"id":"a3","name":"column_mapping","value":"={{ $(\"Mapping Logic\").first().json.column_mapping }}","type":"object"},{"id":"a4","name":"column_dictionary","value":"={{ $(\"Mapping Logic\").first().json.column_dictionary }}","type":"object"},{"id":"a5","name":"total_row_count","value":"={{ $(\"Mapping Logic\").first().json.total_row_count }}","type":"number"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[-176,-192],"id":"4fbccc8c-1cc0-4ff1-b099-6321378fba3f","name":"Set With AI Summary"},{"parameters":{"assignments":{"assignments":[{"id":"b1","name":"dataset_name","value":"={{ $(\"Mapping Logic\").first().json.dataset_name }}","type":"string"},{"id":"b2","name":"dataset_summary","value":"={{ $(\"Mapping Logic\").first().json.dataset_summary }}","type":"string"},{"id":"b6","name":"owner_email","value":"={{ $(\"Mapping Logic\").first().json.owner_email }}","type":"string"},{"id":"b3","name":"column_mapping","value":"={{ $(\"Mapping Logic\").first().json.column_mapping }}","type":"object"},{"id":"b4","name":"column_dictionary","value":"={{ $(\"Mapping Logic\").item.json.column_dictionary }}","type":"object"},{"id":"b5","name":"total_row_count","value":"={{ $(\"Mapping Logic\").first().json.total_row_count }}","type":"number"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[-912,16],"id":"65d0a02a-3b95-4363-8106-4e562525fcb3","name":"Set Without AI"},{"parameters":{"operation":"executeQuery","query":"INSERT INTO n8n_data.dataset_record_manager (\n    dataset_name,\n    dataset_summary,\n    row_count,\n    column_mapping,\n    column_dictionary,\n    owner_email,\n    dataset_desc\n) VALUES ($1, $2, $3, $4::jsonb, $5::jsonb, $6, $7)\nRETURNING dataset_id","options":{"queryReplacement":"={{ [$json.dataset_name, $json.dataset_summary, $json.total_row_count, JSON.stringify($('Mapping Logic').first().json.column_mapping), JSON.stringify($('Mapping Logic').first().json.column_dictionary), $json.owner_email, $('Webhook').first().json.body.dataset_desc] }}"}},"type":"n8n-nodes-base.postgres","typeVersion":2.6,"position":[96,-80],"id":"7a437d0d-d711-4b0c-bb85-53f8d80a8c12","name":"Insert Record Manager","credentials":{"postgres":{"id":"A7zRb9obSaMEyNKs","name":"Postgres account"}}},{"parameters":{"jsCode":"// 1. Get mapping and ID\nconst mappingNode = $(\"Mapping Logic\").first();\nconst managerNode = $(\"Insert Record Manager\").first();\n\nif (!mappingNode || !managerNode) {\n    throw new Error(\"Missing input from Mapping Logic or Insert Record Manager\");\n}\n\nconst mapping = mappingNode.json.column_mapping;\nconst datasetId = managerNode.json.dataset_id;\n\n// --- FIX IS HERE: Reference \"Parse CSV\" directly to get the data rows ---\nconst allRows = $(\"Parse CSV\").all(); \n\nconst results = [];\nconst batchSize = 100; // Smaller batches are safer for large SQL strings\nconst mapEntries = Object.entries(mapping);\nconst dbColumnNames = mapEntries.map(entry => entry[1]);\n\nfunction isDateColumn(colName) {\n    const lower = colName.toLowerCase();\n    return lower.includes(\"date\") || lower.includes(\"_at\") || lower.includes(\"time\");\n}\n\nfunction standardizeDate(val) {\n    const d = new Date(val);\n    return isNaN(d.getTime()) ? null : d.toISOString().split(\"T\")[0];\n}\n\nfunction prepareValue(val, targetColumn) {\n    if (val === null || val === undefined || String(val).trim() === \"\") return \"NULL\";\n    \n    let stringVal = String(val).trim();\n    const colLower = targetColumn.toLowerCase();\n    \n    // Numeric handling (strip currency symbols and commas)\n    if (colLower.startsWith(\"int\") || colLower.startsWith(\"real\") || colLower.startsWith(\"numeric\")) {\n        const cleanNum = stringVal.replace(/[,\\s$]/g, \"\");\n        if (cleanNum === \"\" || isNaN(cleanNum)) return \"NULL\";\n        return cleanNum;\n    }\n    \n    // Date handling\n    if (isDateColumn(targetColumn)) {\n        if (/^\\d+$/.test(stringVal) && parseInt(stringVal) > 9999) return \"NULL\";\n        const correctedDate = standardizeDate(stringVal);\n        return correctedDate ? `'${correctedDate}'` : \"NULL\";\n    }\n    \n    // String handling: Escape single quotes AND dollar signs\n    const escaped = stringVal\n        .replace(/'/g, \"''\")\n        .replace(/\\$/g, \"$$$$\"); \n        \n    return `'${escaped}'`;\n}\n\nconst columns = ['\"dataset_id\"', '\"row_index\"'].concat(dbColumnNames.map(c => `\"${c}\"`));\n\nfor (let i = 0; i < allRows.length; i += batchSize) {\n    const chunk = allRows.slice(i, i + batchSize);\n    const valuesList = chunk.map((item, idx) => {\n        const row = item.json;\n        // Ensure datasetId is wrapped in single quotes as it is a UUID/String\n        const rowValues = [`'${datasetId}'`, i + idx + 1]; \n        \n        mapEntries.forEach(entry => {\n            rowValues.push(prepareValue(row[entry[0]], entry[1]));\n        });\n        return `(${rowValues.join(\",\")})`;\n    });\n\n    results.push({ \n        json: { \n            sql: `INSERT INTO n8n_data.universal_datatable (${columns.join(\",\")}) VALUES ${valuesList.join(\",\")};` \n        } \n    });\n}\n\nreturn results;"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[304,-80],"id":"4907fed9-8291-49ac-96d3-743db8c47a7d","name":"Data Transformer"},{"parameters":{"operation":"executeQuery","query":"{{ $json.sql }}","options":{}},"type":"n8n-nodes-base.postgres","typeVersion":2.6,"position":[496,-80],"id":"bdaa79f1-13c5-46b6-b280-680104cb3cb2","name":"Insert Data","credentials":{"postgres":{"id":"A7zRb9obSaMEyNKs","name":"Postgres account"}}},{"parameters":{"respondWith":"json","responseBody":"={{ { status: \"ok\", datasetId: $(\"Insert Record Manager\").first().json.dataset_id, rowsInserted: $(\"Mapping Logic\").first().json.total_row_count, datasetName:$(\"Mapping Logic\").first().json.dataset_name } }}","options":{}},"type":"n8n-nodes-base.respondToWebhook","typeVersion":1.1,"position":[704,-80],"id":"e009c48c-4770-4d0a-b385-675eadc5d3e5","name":"Respond to Webhook"},{"parameters":{"operation":"executeQuery","query":"=CREATE OR REPLACE VIEW n8n_data.v_ds_{{ $('Insert Record Manager').first().json.dataset_id.replace(/-/g, '_') }} AS\nSELECT\n    {{\n      Object.entries($('Mapping Logic').first().json.column_mapping)\n      .map(([name, col]) => {\n        const safeName = (name && name.trim() !== \"\") ? name.trim() : `unnamed_${col}`;\n        return `${col} AS \"${safeName}\"`;\n      })\n      .join(',\\n    ')\n    }}\nFROM n8n_data.universal_datatable\nWHERE dataset_id = '{{ $('Insert Record Manager').first().json.dataset_id }}';","options":{}},"type":"n8n-nodes-base.postgres","typeVersion":2.6,"position":[608,-80],"id":"84b153c6-eb7b-4ffb-a776-255c07f9180e","name":"Create View","credentials":{"postgres":{"id":"A7zRb9obSaMEyNKs","name":"Postgres account"}}},{"parameters":{"model":{"__rl":true,"value":"kimi-k2.5","mode":"list","cachedResultName":"kimi-k2.5"},"responsesApiEnabled":false,"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[-720,704],"id":"8f6122c3-9b10-430a-87fa-211279d2e843","name":"OpenAI Chat Model1","credentials":{"openAiApi":{"id":"ayhC2xZ3iWv4ZkDW","name":"OpenAi account"}}},{"parameters":{"promptType":"define","text":"=Analyze the following dataset as a single block to build a SQL Search Index:\n{{ JSON.stringify($input.all().map(i => i.json)) }}","needsFallback":true,"options":{"systemMessage":"ROLE\nYou are a Senior Database Engineer and Metadata Architect. Your objective is to analyze a 100-row sample of CSV data and generate a highly structured metadata map. This map will be used by a downstream AI to construct 100% accurate, high-performance SQL queries.\n\nYOUR TASK\nAnalyze the data and identify \"Filtering Columns.\" These are columns used in SQL WHERE, HAVING, or GROUP BY clauses.\n\nCategorical Discovery: Identify columns with low-to-medium cardinality (categories, statuses, regions, types). Extract the exact unique values.\n\nTemporal & Numeric Discovery: Identify date/time columns and numerical columns. Note their exact formatting (e.g., YYYY-MM-DD, presence of $ or , in numbers) so the SQL agent knows how to cast or parse them.\n\nSemantic Mapping: Infer the precise business logic of each column based on its header and values. Do not hallucinate; stick to what the data clearly represents.\n\nData Quality & Quirks: Detect if the column contains empty strings, NULL, N/A, or formatting quirks (e.g., case sensitivity, leading spaces).\n\nGranularity/Double-Counting: Identify rows that represent Subtotals, Totals, or Rollups (e.g., a \"Region\" column that contains the value \"All Regions\").\n\nSTRICT OUTPUT FORMAT\nYou must output strictly valid JSON. Do not include markdown formatting, conversational filler, or explanations. Start immediately with the JSON array [.\n\nUse this exact JSON schema:\n[\n  {\n    \"column_header\": \"Exact Column Name\",\n    \"data_type\": \"Categorical | Date | Numeric | Boolean\",\n    \"business_logic\": \"Brief, precise description of what this filters (e.g., Transaction lifecycle stage).\",\n    \"exact_values\": [\"Value A\", \"Value B\", \"Value C\"], \n    \"format_notes\": \"For Dates: format like MM/DD/YYYY. For Numerics: note currency symbols or commas. For Categories: note case sensitivity or special characters.\",\n    \"null_handling\": \"Note if empty strings, NULLs, or N/A are present.\",\n    \"aggregation_warning\": \"Include specific instructions if this column contains 'Total', 'Subtotal', or 'All' values that must be excluded in standard SUM() queries to avoid double-counting. Otherwise, output null.\"\n  }\n]\n\nCONSTRAINTS:\n\nIgnore purely unique identifiers (e.g., Transaction ID, Employee SSN, full names) UNLESS they are highly relevant for grouping (e.g., Manager ID).\n\nLimit exact_values to a maximum of 15 items. If there are more, list the top 10 and add \"...[High Cardinality]\".\n\nOutput ONLY the raw JSON array.","maxIterations":25,"returnIntermediateSteps":false}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3.1,"position":[-720,-240],"id":"acc77dae-8083-4fa7-bbba-6cd7421f8ad7","name":"AI Agent","executeOnce":true},{"parameters":{"jsCode":"var rawText = $json.output || \"\";\n\n// 1. Strip any markdown formatting the AI might add (e.g., ```json ... ```)\nvar jsonString = rawText.replace(/```[a-z]*\\n?/g, \"\").replace(/```/g, \"\").trim();\n\nvar parsedData;\ntry {\n  // 2. Parse the pure JSON array\n  parsedData = JSON.parse(jsonString);\n} catch (e) {\n  // Safe fallback if the AI hallucinates bad JSON\n  return { cleaned_summary: \"Error parsing AI output: \" + e.message + \"\\n\\nRaw Output:\\n\" + rawText };\n}\n\nvar mdRows = [];\n\n// 3. Loop through the JSON objects and build your clean Markdown string\nparsedData.forEach(function(col) {\n  var sectionMd = \"### Column name:\" + col.column_header + \"\\n\";\n  \n  if (col.data_type) sectionMd += \"* **Data Type:** \" + col.data_type + \"\\n\";\n  if (col.business_logic) sectionMd += \"* **Business Logic:** \" + col.business_logic + \"\\n\";\n  \n  // Join the array of exact values with commas\n  if (col.exact_values && col.exact_values.length > 0) {\n    sectionMd += \"* **Exact Values:** \" + col.exact_values.join(\", \") + \"\\n\";\n  }\n  \n  if (col.format_notes) sectionMd += \"* **Format Notes:** \" + col.format_notes + \"\\n\";\n  if (col.null_handling) sectionMd += \"* **Null Handling:** \" + col.null_handling + \"\\n\";\n  if (col.aggregation_warning) sectionMd += \"* **Aggregation Warning:** \" + col.aggregation_warning + \"\\n\";\n  \n  mdRows.push(sectionMd);\n});\n\n// 4. Return the formatted markdown string to be passed to Postgres\nreturn { cleaned_summary: mdRows.join(\"\\n\\n\") };"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[-400,-272],"id":"78383b03-14af-4c27-8d66-1587e800ff42","name":"Clean Summary"}],"pinData":{},"connections":{"OpenAI Chat Model":{"ai_languageModel":[[{"node":"AI Agent","type":"ai_languageModel","index":0}]]},"Webhook":{"main":[[{"node":"Parse CSV","type":"main","index":0}]]},"Parse CSV":{"main":[[{"node":"Mapping Logic","type":"main","index":0}]]},"Mapping Logic":{"main":[[{"node":"If Summary Empty","type":"main","index":0}]]},"If Summary Empty":{"main":[[{"node":"Sample Data","type":"main","index":0}],[{"node":"Set Without AI","type":"main","index":0}]]},"Sample Data":{"main":[[{"node":"AI Agent","type":"main","index":0}]]},"Set With AI Summary":{"main":[[{"node":"Insert Record Manager","type":"main","index":0}]]},"Set Without AI":{"main":[[{"node":"Insert Record Manager","type":"main","index":0}]]},"Insert Record Manager":{"main":[[{"node":"Data Transformer","type":"main","index":0}]]},"Data Transformer":{"main":[[{"node":"Insert Data","type":"main","index":0}]]},"Insert Data":{"main":[[{"node":"Create View","type":"main","index":0}]]},"Create View":{"main":[[{"node":"Respond to Webhook","type":"main","index":0}]]},"OpenAI Chat Model1":{"ai_languageModel":[[{"node":"AI Agent","type":"ai_languageModel","index":1}]]},"AI Agent":{"main":[[{"node":"Clean Summary","type":"main","index":0}]]},"Clean Summary":{"main":[[{"node":"Set With AI Summary","type":"main","index":0}]]}},"active":true,"settings":{"executionOrder":"v1","binaryMode":"separate","availableInMCP":false},"versionId":"efb32c52-84b4-4519-819b-cdd6b653954a","meta":{"templateCredsSetupCompleted":true,"instanceId":"558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a"},"id":"tgKjDasZvFZqdkPg","tags":[]}